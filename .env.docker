# Server configuration
HOST=0.0.0.0  # IMPORTANT: 0.0.0.0 để accessible từ bên ngoài container
PORT=8000
DEBUG=false  # Production mode

# Ollama/LLM configuration
OLLAMA_BASE_URL=http://192.168.200.135:11434/v1  # Cho Docker Desktop
# Nếu chạy Ollama trên cùng EC2 nhưng ngoài Docker:
# OLLAMA_BASE_URL=http://172.17.0.1:11434/v1  # Docker bridge network

OLLAMA_API_KEY=ollama
OLLAMA_MODEL=gpt-oss:20b  # Hoặc model bạn muốn dùng

# AI settings
AI_MAX_TOKENS=4000
AI_TEMPERATURE=0.7

# Prompt file paths
AI_CODE_REVIEW_PROMPT_FILE=prompt.txt